{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0222aa9",
   "metadata": {},
   "source": [
    "# Crowdless — Crowdness Demo\n",
    "\n",
    "End-to-end notebook for training, exploring, and predicting a **crowdness score** from generic per-area time series JSON files under `./areas_output`.\n",
    "\n",
    "**Input JSON expectation**\n",
    "- Each file: `{ \"area\": \"<name>\", \"items\": [ { \"datetime\": \"...\", \"<field_a>\": <number>, \"<field_b>\": <number> }, ... ] }`\n",
    "- Use `FIELD_MAP` below to map your JSON field names to `feature_x` and `feature_y`. Default mapping aligns with the current test files.\n",
    "\n",
    "**Outputs**\n",
    "- `areas_output/metrics_database.pkl` — processed DataFrame for fast lookup\n",
    "- `areas_output/crowdness_model.json` — simple, tunable scoring rule parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87100734",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally and you need packages, uncomment:\n",
    "# %pip install pandas numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e870c",
   "metadata": {},
   "source": [
    "## Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47472292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AREAS_DIR = Path(\"./areas_output\")\n",
    "\n",
    "# File outputs\n",
    "DB_FILE = AREAS_DIR / \"metrics_database.pkl\"\n",
    "MODEL_FILE = AREAS_DIR / \"crowdness_model.json\"\n",
    "\n",
    "# Map your JSON numeric fields to generic features used by the model.\n",
    "# Defaults match current test data; change as needed.\n",
    "FIELD_MAP = {\n",
    "    \"feature_x\": \"temperature_celsius\",          # rename to your field name\n",
    "    \"feature_y\": \"relative_humidity_percent\",    # rename to your field name\n",
    "}\n",
    "\n",
    "AREAS_DIR, DB_FILE, MODEL_FILE, FIELD_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd6c36",
   "metadata": {},
   "source": [
    "## Build database from JSON files (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ab1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(areas_dir: Path, db_path: Path, field_map: Dict[str, str]) -> pd.DataFrame:\n",
    "    json_files = list(areas_dir.glob(\"*.json\"))\n",
    "    skip_files = {db_path.name, MODEL_FILE.name, \"crowdness_scores.json\"}\n",
    "    rows = []\n",
    "\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"No JSON files found in {areas_dir.resolve()}.\")\n",
    "\n",
    "    for f in json_files:\n",
    "        if f.name in skip_files:\n",
    "            continue\n",
    "        try:\n",
    "            with open(f, \"r\", encoding=\"utf-8\") as fh:\n",
    "                data = json.load(fh)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {f.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        area = data.get(\"area\")\n",
    "        if not area:\n",
    "            print(f\"Skipping {f.name}: missing 'area'\")\n",
    "            continue\n",
    "\n",
    "        fx_key = field_map[\"feature_x\"]\n",
    "        fy_key = field_map[\"feature_y\"]\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            dt = item.get(\"datetime\")\n",
    "            fx = item.get(fx_key)\n",
    "            fy = item.get(fy_key)\n",
    "            if dt and fx is not None and fy is not None:\n",
    "                rows.append({\n",
    "                    \"area\": area,\n",
    "                    \"datetime\": pd.to_datetime(dt, utc=True),\n",
    "                    \"feature_x\": float(fx),\n",
    "                    \"feature_y\": float(fy),\n",
    "                })\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No valid rows found in JSONs for the configured FIELD_MAP.\")\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(rows)\n",
    "        .dropna()\n",
    "        .drop_duplicates(subset=[\"area\", \"datetime\"])\n",
    "        .set_index(\"datetime\")\n",
    "    )\n",
    "\n",
    "    df.to_pickle(db_path)\n",
    "    return df\n",
    "\n",
    "def default_model() -> Dict[str, float]:\n",
    "    return {\n",
    "        # Generic triangular scoring around an ideal point\n",
    "        # feature_x: score 1.0 at ideal_x, 0.0 at ideal_x ± range_x\n",
    "        \"ideal_x\": 22.0,\n",
    "        \"range_x\": 15.0,\n",
    "\n",
    "        # feature_y: penalize only when above ideal_y; 1.0 when <= ideal_y; 0.0 at ideal_y + range_y\n",
    "        \"ideal_y\": 45.0,\n",
    "        \"range_y\": 50.0,\n",
    "\n",
    "        # Weights in the final score\n",
    "        \"weight_x\": 0.7,\n",
    "        \"weight_y\": 0.3,\n",
    "    }\n",
    "\n",
    "def save_model(model: Dict[str, float], path: Path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(model, fh, indent=2)\n",
    "\n",
    "try:\n",
    "    df_trained = build_database(AREAS_DIR, DB_FILE, FIELD_MAP)\n",
    "    model_rules = default_model()\n",
    "    save_model(model_rules, MODEL_FILE)\n",
    "    print(f\"Saved {len(df_trained)} rows to {DB_FILE}\")\n",
    "    print(f\"Saved model to {MODEL_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Train step: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145591f",
   "metadata": {},
   "source": [
    "## Explore database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(db_path: Path) -> pd.DataFrame:\n",
    "    return pd.read_pickle(db_path)\n",
    "\n",
    "def coverage_by_area(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    agg = df.reset_index().groupby(\"area\").agg(\n",
    "        start=(\"datetime\", \"min\"),\n",
    "        end=(\"datetime\", \"max\"),\n",
    "        rows=(\"datetime\", \"count\"),\n",
    "        mean_x=(\"feature_x\", \"mean\"),\n",
    "        mean_y=(\"feature_y\", \"mean\"),\n",
    "    ).sort_values(\"area\")\n",
    "    return agg\n",
    "\n",
    "if DB_FILE.exists():\n",
    "    db = load_db(DB_FILE)\n",
    "    cov = coverage_by_area(db)\n",
    "    display(cov)\n",
    "else:\n",
    "    print(\"Database not found. Run the train cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2858fcd",
   "metadata": {},
   "source": [
    "## Scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path: Path) -> Dict[str, float]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        return json.load(fh)\n",
    "\n",
    "def score_from_features(feature_x: float, feature_y: float, model: Dict[str, float]) -> float:\n",
    "    # feature_x triangular score\n",
    "    x_ideal = model[\"ideal_x\"]\n",
    "    x_range = model[\"range_x\"]\n",
    "    x_score = max(0.0, 1.0 - abs(feature_x - x_ideal) / x_range)\n",
    "\n",
    "    # feature_y penalty when above ideal\n",
    "    y_ideal = model[\"ideal_y\"]\n",
    "    y_range = model[\"range_y\"]\n",
    "    if feature_y > y_ideal:\n",
    "        y_score = max(0.0, 1.0 - (feature_y - y_ideal) / y_range)\n",
    "    else:\n",
    "        y_score = 1.0\n",
    "\n",
    "    wx = model[\"weight_x\"]\n",
    "    wy = model[\"weight_y\"]\n",
    "    final = (x_score * wx + y_score * wy) * 100.0\n",
    "    return float(final)\n",
    "\n",
    "if MODEL_FILE.exists():\n",
    "    mdl = load_model(MODEL_FILE)\n",
    "    print(mdl)\n",
    "else:\n",
    "    print(\"Model file not found. Run the train cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32532817",
   "metadata": {},
   "source": [
    "### Score vs. feature_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FILE.exists():\n",
    "    mdl = load_model(MODEL_FILE)\n",
    "    xs = np.linspace(-5, 45, 300)\n",
    "    y_fixed = mdl[\"ideal_y\"]\n",
    "    scores = [score_from_features(x, y_fixed, mdl) for x in xs]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(xs, scores)\n",
    "    plt.xlabel(\"feature_x\")\n",
    "    plt.ylabel(\"Score (0–100)\")\n",
    "    plt.title(\"Score vs feature_x (feature_y fixed at ideal_y)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac250c62",
   "metadata": {},
   "source": [
    "### Score vs. feature_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9889b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FILE.exists():\n",
    "    mdl = load_model(MODEL_FILE)\n",
    "    ys = np.linspace(0, 100, 300)\n",
    "    x_fixed = mdl[\"ideal_x\"]\n",
    "    scores = [score_from_features(x_fixed, y, mdl) for y in ys]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(ys, scores)\n",
    "    plt.xlabel(\"feature_y\")\n",
    "    plt.ylabel(\"Score (0–100)\")\n",
    "    plt.title(\"Score vs feature_y (feature_x fixed at ideal_x)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb99b1f",
   "metadata": {},
   "source": [
    "### Score heatmap (feature_x × feature_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e33b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_FILE.exists():\n",
    "    mdl = load_model(MODEL_FILE)\n",
    "    xs = np.linspace(-5, 45, 101)\n",
    "    ys = np.linspace(0, 100, 101)\n",
    "    grid = np.zeros((len(ys), len(xs)))\n",
    "    for i, y in enumerate(ys):\n",
    "        for j, x in enumerate(xs):\n",
    "            grid[i, j] = score_from_features(x, y, mdl)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(grid, origin='lower', aspect='auto', extent=[xs.min(), xs.max(), ys.min(), ys.max()])\n",
    "    plt.colorbar(label=\"Score (0–100)\")\n",
    "    plt.xlabel(\"feature_x\")\n",
    "    plt.ylabel(\"feature_y\")\n",
    "    plt.title(\"Score heatmap\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714e870",
   "metadata": {},
   "source": [
    "## Predict for an area and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_area_time(area: str, dt: str, db: pd.DataFrame, model: Dict[str, float]) -> dict:\n",
    "    input_dt = pd.to_datetime(dt, utc=True)\n",
    "    area_db = db[db['area'].str.lower() == area.lower()]\n",
    "    if area_db.empty:\n",
    "        raise ValueError(f\"No data for area '{area}'. Available: {sorted(set(db['area']))}\")\n",
    "\n",
    "    idx = area_db.index.get_indexer([input_dt], method='nearest')[0]\n",
    "    if idx == -1:\n",
    "        raise RuntimeError(\"Could not find nearest timestamp.\")\n",
    "\n",
    "    row = area_db.iloc[idx]\n",
    "    matched_time = row.name\n",
    "    fx = float(row['feature_x'])\n",
    "    fy = float(row['feature_y'])\n",
    "    score = score_from_features(fx, fy, model)\n",
    "\n",
    "    return {\n",
    "        \"input_area\": area,\n",
    "        \"input_time\": input_dt.isoformat(),\n",
    "        \"matched_time\": matched_time.isoformat(),\n",
    "        \"time_diff\": str(abs(matched_time - input_dt)),\n",
    "        \"area_canonical\": row['area'],\n",
    "        \"feature_x\": fx,\n",
    "        \"feature_y\": fy,\n",
    "        \"score\": score,\n",
    "    }\n",
    "\n",
    "try:\n",
    "    if DB_FILE.exists() and MODEL_FILE.exists():\n",
    "        db = pd.read_pickle(DB_FILE)\n",
    "        mdl = load_model(MODEL_FILE)\n",
    "        example = predict_area_time(\"Syntagma\", \"2025-07-01T13:00:00Z\", db, mdl)\n",
    "        example\n",
    "    else:\n",
    "        print(\"Run training first.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7184ef",
   "metadata": {},
   "source": [
    "### Batch scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae237f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(pairs, db: pd.DataFrame, model: Dict[str, float]):\n",
    "    out = []\n",
    "    for area, dt in pairs:\n",
    "        try:\n",
    "            out.append(predict_area_time(area, dt, db, model))\n",
    "        except Exception as e:\n",
    "            out.append({\"input_area\": area, \"input_time\": dt, \"error\": str(e)})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "try:\n",
    "    if DB_FILE.exists() and MODEL_FILE.exists():\n",
    "        db = pd.read_pickle(DB_FILE)\n",
    "        mdl = load_model(MODEL_FILE)\n",
    "        sample_pairs = [\n",
    "            (\"Syntagma\", \"2025-07-01T10:00:00Z\"),\n",
    "            (\"Syntagma\", \"2025-07-01T18:00:00Z\"),\n",
    "            (\"Kallithea\", \"2025-08-15T09:00:00Z\"),\n",
    "        ]\n",
    "        batch_df = batch_predict(sample_pairs, db, mdl)\n",
    "        display(batch_df)\n",
    "    else:\n",
    "        print(\"Run training first.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428040e",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Adjust `FIELD_MAP` to point to the numeric fields you want to use as `feature_x` and `feature_y`.\n",
    "- Tune `MODEL_FILE` parameters to change the shape and weights of the scoring function.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
